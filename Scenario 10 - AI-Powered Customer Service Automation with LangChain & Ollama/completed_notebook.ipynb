{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0255588",
   "metadata": {},
   "source": [
    "## üõçÔ∏è AI Assistant for E-Commerce Customer Support\n",
    "\n",
    "You've just joined **Trendora**, a fast-growing e-commerce startup known for its trendy gadgets and same-day delivery promise. The support team is overwhelmed with customer messages‚Äîranging from product inquiries to returns and even pirate-style rants from angry customers.\n",
    "\n",
    "Your manager wants to **automate parts of the customer service pipeline** using local language models to save on API costs and increase data privacy.\n",
    "\n",
    "You‚Äôll be working with **LangChain + Ollama**, using **Meta's LLaMA 3.2 model** running locally.\n",
    "\n",
    "Your mission is to:\n",
    "\n",
    "- Generate consistent and polite responses to customer emails using custom prompt templates.\n",
    "- Translate angry or informal emails into professional English.\n",
    "- Extract structured info (like refund intent, product issue, delivery time) from unstructured reviews.\n",
    "- Make sure everything runs locally for cost and compliance reasons.\n",
    "\n",
    "Let‚Äôs dive into it and start building a smart, private-first language assistant for Trendora‚Äôs e-commerce operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4111ec08",
   "metadata": {},
   "source": [
    "Let's install the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94525751",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain_core langchain_ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd9d17",
   "metadata": {},
   "source": [
    "Let's import the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831127b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2:latest\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a97884",
   "metadata": {},
   "source": [
    "Let‚Äôs start by sending a basic prompt to our locally running model to see if it works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7259912",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is 1 + 1?\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df12ea94",
   "metadata": {},
   "source": [
    "Your boss just asked you to handle a customer complaint. A customer sent a very upset message about a defective gadget. Your task is to translate their message into a calm and polite tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08347fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "I am furious! I ordered your wireless speaker and the battery died in two hours. This is ridiculous. I want a refund NOW!\n",
    "\"\"\"\n",
    "\n",
    "style = \"American English in a calm and respectful tone\"\n",
    "\n",
    "prompt = f\"\"\"Translate the text delimited by triple backticks into a style that is {style}.\n",
    "text: ```{customer_email}```\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b6394",
   "metadata": {},
   "source": [
    "We can see that the model successfully rewrote the email in a more professional and respectful tone while keeping the original message intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc0e3f",
   "metadata": {},
   "source": [
    "Now, what if your boss asks you to process multiple angry emails every day?\n",
    "\n",
    "Instead of writing a new prompt each time, you can use LangChain‚Äôs `PromptTemplate` to build a reusable template. let me show you how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text delimited by triple backticks into a style that is {style}. text: ```{text}```\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template_string)\n",
    "\n",
    "formatted_prompt = prompt_template.format(\n",
    "\tstyle=style,\n",
    "\ttext=customer_email\n",
    ")\n",
    "\n",
    "response = llm.invoke(formatted_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8207861",
   "metadata": {},
   "source": [
    "This way, we can use the `format` function to fill in the prompt template whenever needed.\n",
    "\n",
    "This time, imagine you‚Äôve received an email from a customer who‚Äôs having trouble with a recently purchased smartwatch. Instead of rewriting the prompt from scratch, you simply plug the message and desired tone into the template. here is how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47935cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Dear customer, thank you for contacting us. We're sorry to hear that your smartwatch is not charging properly. \n",
    "Please try using a different charging cable and make sure the contact points are clean. \n",
    "If the issue persists, you can request a replacement through our support center.\"\"\"\n",
    "\n",
    "service_style_friendly = \"a warm and understanding tone in American English, suitable for customer support\"\n",
    "\n",
    "formatted_service_prompt = prompt_template.format(\n",
    "\tstyle=service_style_friendly,\n",
    "\ttext=service_reply\n",
    ")\n",
    "\n",
    "response = llm.invoke(formatted_service_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d5965b",
   "metadata": {},
   "source": [
    "Now You‚Äôre tasked with extracting structured information from product reviews ‚Äî such as whether the item was a gift, how long delivery took, and how the customer perceived the product‚Äôs price or value.\n",
    "\n",
    "Let me show you how you can get your response with a json structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\n",
    "This air fryer is amazing. My husband got it as a gift for our anniversary and it arrived within 3 days. It‚Äôs a bit pricey, but honestly worth every penny.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON.\n",
    "\n",
    "text: {text}\n",
    "\"\"\"\n",
    "\n",
    "review_prompt = PromptTemplate.from_template(review_template)\n",
    "formatted_review = review_prompt.format(text=customer_review)\n",
    "\n",
    "response = llm.invoke(formatted_review)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910d7d4",
   "metadata": {},
   "source": [
    "Your boss wants to know: what if the LLM returns a JSON response with the wrong structure for example missing keys or inconsistent formatting?\n",
    "\n",
    "To make the output reliable and consistent, we need a way to enforce the correct JSON structure every time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcb8a4",
   "metadata": {},
   "source": [
    "To do this we can use `Langchain Output Parsers`. let's import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac979719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47612406",
   "metadata": {},
   "source": [
    "To make sure the JSON output from the language model always follows a consistent structure, we can define a set of response schemas using `ResponseSchema`. Each schema specifies a key we expect in the output and describes what it should contain.\n",
    "\n",
    "This allows us to generate a clear set of formatting instructions that guide the model to return data in a predictable and structured way ‚Äî making it much easier to parse the results programmatically.\n",
    "\n",
    "Let‚Äôs define the expected fields:  \n",
    "- `gift`: whether the item was purchased as a gift  \n",
    "- `delivery_days`: how many days it took to arrive  \n",
    "- `price_value`: comments related to price or value\n",
    "\n",
    "So now, let's do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ff5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(\n",
    "\tname=\"gift\",\n",
    "\tdescription=\"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\"\n",
    ")\n",
    "\n",
    "delivery_days_schema = ResponseSchema(\n",
    "\tname=\"delivery_days\",\n",
    "\tdescription=\"How many days did it take for the product to arrive? If this info is not found, output -1.\"\n",
    ")\n",
    "\n",
    "price_value_schema = ResponseSchema(\n",
    "\tname=\"price_value\",\n",
    "\tdescription=\"Extract any sentences about the value or price, output as comma separated list.\"\n",
    ")\n",
    "\n",
    "response_schemas = [gift_schema, delivery_days_schema, price_value_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440bdb3",
   "metadata": {},
   "source": [
    "Now let's have a look at the `response` with json object again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9537b1d6",
   "metadata": {},
   "source": [
    "Now we can use the output parser to parse the response into a `python dictionary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e730367",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response)\n",
    "print(\"parsed output:\", output_dict)\n",
    "print(\"type of the output: \" , type(output_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39240276",
   "metadata": {},
   "source": [
    "So as you can see result is a structured and easy-to-use Python dictionary (`dict`), which can now be passed into databases, used for analytics, or integrated into automated workflows."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
